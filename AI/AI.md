---
---


*Meaning Is Intrinsic If Intelligence Is Natural*

https://eugeneyan.com/writing/llm-patterns/

"The trouble is that nobody knows exactly how large language models work."

Small changes to a test can dramatically impact scores. This suggests they may be relying on shortcuts or brute force statistical approaches rather than true comprehension.

As long as the primary objective for using artificial intelligence is to cut costs or increase profit, the tests will always carry an inherent bias, which, for the purpose of creating functional, quote-unquote, artificial general intelligence,


People like Sam Altman, who are addicted to the attention they receive from making grandiose predictions, need to be pressed harder for actual answers to basic questions like "how does this work?". The fact that he can't explain how Language Models work is astounding given that he takes so so much credit for the advancement in this field. We really need to stop listening to spoiled children of silicon valley when it comes to the realistic


## palm2

#palm2 #llm #gpt #vscode

[colab example](https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/examples/text_calculator.ipynb)
[vscode extension](https://developers.generativeai.google/develop/sample-apps/pipet-code-agent)
[playground](https://makersuite.google.com/app/prompts/simple-summarizer)
