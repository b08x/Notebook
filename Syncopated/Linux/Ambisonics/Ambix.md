
## ambiscraper

https://github.com/andresperezlopez/ambiscaper

> Ambiscaper: a tool for automatic dataset generation and annotation of reverberant Ambisonics audio


https://ambiscaper.readthedocs.io/en/latest/tutorial.html


### datasets

https://webfiles.york.ac.uk/OPENAIR/Anechoic/

https://zenodo.org/record/1186907/files/database.zip?download=1
https://zenodo.org/record/1186905/files/anechoic_openAIRlib_ccsa.zip?download=1

https://zenodo.org/record/4642005


```
It's a rainy Tuesday morning in Columbus, OH. The ambience is that of a linux hacker space.  Today we will be exploring the capabilities of DeepAFx, an intriguing new Python library that combines deep learning and audio effects plugins. Developed by researchers, DeepAFx allows audio effects like reverb or distortion to be integrated as layers within neural networks. This enables some fascinating new possibilities for audio processing.

The creators of DeepAFx have achieved this integration through leveraging two key technologies - the popular TensorFlow machine learning library, and the Linux Audio Developers' LV2 standard for audio plugins. By bringing together these two worlds, DeepAFx opens the door to AI-driven audio effects.

We’ll be taking a close look at how DeepAFx works under the hood, and testing out some of the audio manipulations it can perform when effects plugins are chained together into neural networks. Later on, we’ll discuss how this technology could be adapted for workflows like automating ambisonic productions on Linux-based DAWs.
```