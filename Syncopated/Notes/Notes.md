
https://elevenlabs.io/speech-synthesis

https://asciiflow.com/#/
https://asciiflow.com/legacy/


cachy --> ansible --> linux audio --> deadbeef --> sonic-visualizer -->  midi? --(GPT)-> sonic-pi

document processing --> llm memory (RAG/Cache) --> monadic

flowise --> prompt chaining

[Phoenix: AI Observability & Evaluation](https://docs.arize.com/phoenix/)



live recording --> generated beats(sonicpi) --> wavjourney --> sonic vis|tony --> ocenaudio


---

## how the use commas in day to day life mirror the behavior of LLMs

https://www.bbc.com/worklife/article/20180723-the-commas-that-cost-companies-millions


[ai and me: 222 days of prompt engineering](https://medium.com/aimonks/ai-and-me-222-days-of-prompt-engineering-19c4ec1a3eca)



## deadbeef and sonic-visualiser

